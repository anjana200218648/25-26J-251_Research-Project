#!/usr/bin/env python3\n\"\"\"\nModel Service Connectivity Test Script\n\nThis script tests the improved model loading functionality with timeout handling,\nretry logic, and fallback models.\n\"\"\"\n\nimport sys\nimport os\n\n# Add the backend directory to the Python path\nsys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))\n\nfrom model_service import ModelService, check_model_cache_status\nimport json\n\ndef test_connectivity():\n    \"\"\"Test connectivity and cache status\"\"\"\n    print(\"=\"*60)\n    print(\"üîç CONNECTIVITY & CACHE DIAGNOSIS\")\n    print(\"=\"*60)\n    \n    # Check cache status\n    cache_status = check_model_cache_status()\n    print(\"\\nüìÅ Cache Status:\")\n    for model_type, is_cached in cache_status.items():\n        status_emoji = \"‚úÖ\" if is_cached else \"‚ùå\"\n        print(f\"   {status_emoji} {model_type}: {'Cached' if is_cached else 'Not cached'}\")\n    \n    # Initialize model service and run diagnosis\n    model_service = ModelService()\n    diagnosis = model_service.diagnose_connectivity()\n    \n    print(f\"\\nüåê Connectivity Status: {diagnosis['connectivity_status']}\")\n    print(f\"üîÑ Can Work Offline: {'Yes' if diagnosis['can_work_offline'] else 'No'}\")\n    \n    print(\"\\nüí° Recommendations:\")\n    for rec in diagnosis['recommendations']:\n        print(f\"   {rec}\")\n    \n    return diagnosis\n\ndef test_model_loading():\n    \"\"\"Test model loading with improved timeout handling\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"ü§ñ MODEL LOADING TEST\")\n    print(\"=\"*60)\n    \n    try:\n        model_service = ModelService()\n        print(\"\\nüöÄ Attempting to load model with improved timeout handling...\")\n        model_service.load_model()\n        \n        if model_service._loaded:\n            print(\"\\n‚úÖ SUCCESS: Model loaded successfully!\")\n            print(f\"   - Device: {model_service.device}\")\n            print(f\"   - Tokenizer: {'Loaded' if model_service.tokenizer else 'Failed'}\")\n            print(f\"   - Model: {'Loaded' if model_service.model else 'Failed'}\")\n            print(f\"   - Encoders: {len(model_service.encoders)} loaded\")\n            \n            # Test a simple prediction to ensure everything works\n            test_text = \"My child spends too much time on social media and is neglecting homework\"\n            test_features = {\n                'age_of_child': 14,\n                'hours_per_day_on_social_media': 8,\n                'child_gender': 'F',\n                'reporter_role': 'parent',\n                'device_type': 'mobile'\n            }\n            \n            print(\"\\nüß™ Testing prediction functionality...\")\n            try:\n                result = model_service.predict(test_text, test_features)\n                print(\"‚úÖ Prediction test successful!\")\n                print(f\"   Risk Level: {result.get('risk_level', 'Unknown')}\")\n                print(f\"   Confidence: {result.get('confidence', 'Unknown')}\")\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Prediction test failed: {e}\")\n            \n            return True\n        else:\n            print(\"‚ùå FAILED: Model loading failed\")\n            return False\n            \n    except Exception as e:\n        print(f\"‚ùå ERROR during model loading: {e}\")\n        print(\"\\nüîß Troubleshooting suggestions:\")\n        print(\"   1. Check your internet connection\")\n        print(\"   2. Try running the script again (models will be cached)\")\n        print(\"   3. If this persists, the Hugging Face servers might be down\")\n        print(\"   4. Check the connectivity diagnosis above for more details\")\n        return False\n\ndef main():\n    \"\"\"Main test function\"\"\"\n    print(\"üî¨ Model Service Connectivity Test\")\n    print(f\"Python version: {sys.version}\")\n    print(f\"Working directory: {os.getcwd()}\")\n    \n    # Test 1: Connectivity and cache diagnosis\n    diagnosis = test_connectivity()\n    \n    # Test 2: Model loading \n    success = test_model_loading()\n    \n    # Summary\n    print(\"\\n\" + \"=\"*60)\n    print(\"üìä TEST SUMMARY\")\n    print(\"=\"*60)\n    \n    if success:\n        print(\"‚úÖ All tests passed! The model service is working correctly.\")\n        if diagnosis['connectivity_status'] == 'offline' and diagnosis['can_work_offline']:\n            print(\"üîÆ Note: Working in offline mode using cached models\")\n    else:\n        print(\"‚ùå Tests failed. Please check the error messages above.\")\n        \n        if diagnosis['connectivity_status'] == 'offline' and not diagnosis['can_work_offline']:\n            print(\"\\nüí° SOLUTION: Connect to internet and run once to cache models\")\n        elif diagnosis['connectivity_status'] == 'online':\n            print(\"\\nüí° SOLUTION: This might be a temporary Hugging Face server issue\")\n            print(\"   Try running the script again in a few minutes\")\n    \n    print(\"\\n\" + \"=\"*60)\n    return success\n\nif __name__ == \"__main__\":\n    main()\n